Tapping behavorial data streams: basic methods demonstrating how to utilize proximal sensors for human motion analysis.

* proximal sensors
  * cheap
  * ubiquotous
  * powerful

* motion
* orientation
* geolocation

Proximal sensors enable us to readily capture many different types of behavioral data streams.  We can utilize these behavioral data streams for research purposes.  Here we focus on their use for creating multimodal datasets for human motion analysis.

In particular, we'd like to demonstrate some basic methods for capturing,
filtering, synchronizing, rendering, extracting, analyzing, and replicating the
behavioral data streams afforded by proximal sensors.

* the synchronization of multiple modalities
* timed metadata
* coordinated views

Event Streams
Node/Streams
D3/Crossfilter
WebRTC
LevelDB/IndexedDB
Tracks/Cues/[WebVTT](https://developer.mozilla.org/en-US/docs/HTML/WebVTT)

